{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, OneHotEncoder, StandardScaler, OneHotEncoder\n",
    "\n",
    "dataset1_url = \"https://raw.githubusercontent.com/hbedros/data622-assignment4/main/data/dataset1.csv\"\n",
    "dataset2_url = \"https://raw.githubusercontent.com/hbedros/data622-assignment4/main/data/dataset2.csv\"\n",
    "\n",
    "response1 = requests.get(dataset1_url, verify=False)\n",
    "response2 = requests.get(dataset2_url, verify=False)\n",
    "\n",
    "data1 = StringIO(response1.text)\n",
    "data2 = StringIO(response2.text)\n",
    "dataset1 = pd.read_csv(data1)\n",
    "dataset2 = pd.read_csv(data2)\n",
    "\n",
    "\n",
    "\n",
    "## Cleaning Dataset 1 - The Depression Dataset\n",
    "\n",
    "df1 = pd.DataFrame(dataset1)\n",
    "df1.columns = df1.columns.str.strip()\n",
    "df1 = df1.rename(columns = {'Have you ever had suicidal thoughts ?':'suicidal thoughts'})\n",
    "df1['Sleep Duration'] = pd.Categorical(df1['Sleep Duration'], categories=['Less than 5 hours', '5-6 hours', '7-8 hours', 'More than 8 hours'])\n",
    "\n",
    "numeric_cols_df1 = ['Age', 'Academic Pressure', 'Study Satisfaction', 'Study Hours', 'Financial Stress']\n",
    "categorical_cols_df1 = ['Gender', 'Sleep Duration', 'Dietary Habits', 'suicidal thoughts', 'Family History of Mental Illness', 'Depression']\n",
    "scaler = MinMaxScaler()\n",
    "df1[numeric_cols_df1] = scaler.fit_transform(df1[numeric_cols_df1])\n",
    "\n",
    "df2 = pd.DataFrame(dataset2)\n",
    "df2.columns = df2.columns.str.strip()\n",
    "\n",
    "def parse_range(val):\n",
    "    if isinstance(val, str) and \"-\" in val:\n",
    "        lower, upper = map(float, val.split(\"-\"))\n",
    "        return (lower + upper) / 2\n",
    "    else:\n",
    "        return float(val)\n",
    "\n",
    "df2[\"cgpa\"] = df2[\"cgpa\"].apply(parse_range)\n",
    "\n",
    "def parse_sleep(val):\n",
    "    if isinstance(val, str) and \"hrs\" in val:\n",
    "        val = val.replace(\" hrs\", \"\").strip()\n",
    "    if \"-\" in val:\n",
    "        lower, upper = map(float, val.split(\"-\"))\n",
    "        return (lower + upper) / 2\n",
    "    else:\n",
    "        return float(val)\n",
    "\n",
    "if \"average_sleep\" in df2.columns:\n",
    "    df2[\"average_sleep\"] = df2[\"average_sleep\"].apply(parse_sleep)\n",
    "\n",
    "numerical_cols = [\n",
    "    \"cgpa\", \"study_satisfaction\", \"average_sleep\"\n",
    "]\n",
    "\n",
    "missing_cols = [col for col in numerical_cols if col not in df2.columns]\n",
    "if missing_cols:\n",
    "    print(\"Missing columns after cleaning:\", missing_cols)\n",
    "else:\n",
    "    scaler = MinMaxScaler()\n",
    "    df2[numerical_cols] = scaler.fit_transform(df2[numerical_cols])\n",
    "\n",
    "if \"stress_relief_activities\" in df2.columns:\n",
    "    activities = df2[\"stress_relief_activities\"].str.get_dummies(sep=\",\")\n",
    "    \n",
    "    df2 = pd.concat([df2, activities], axis=1)\n",
    "    \n",
    "\n",
    "def parse_sports_engagement(val):\n",
    "    if isinstance(val, str):\n",
    "        val = val.strip().lower()  # Normalize the input\n",
    "        if \"no sports\" in val:\n",
    "            return 0.0  # Assign 0 for 'No Sports'\n",
    "        elif \"-\" in val:\n",
    "            # Handle ranges like \"1-3 times\"\n",
    "            try:\n",
    "                lower, upper = map(float, val.replace(\" times\", \"\").split(\"-\"))\n",
    "                return (lower + upper) / 2\n",
    "            except ValueError:\n",
    "                return np.nan  # Handle malformed ranges\n",
    "        elif \"7+\" in val or \"7+s\" in val:\n",
    "            # Assign a numeric value for '7+' or '7+s'\n",
    "            return 7.5\n",
    "        elif \"time\" in val:\n",
    "            # Handle single occurrences like \"1 time\"\n",
    "            try:\n",
    "                return float(val.replace(\" time\", \"\").strip())\n",
    "            except ValueError:\n",
    "                return np.nan\n",
    "    try:\n",
    "        return float(val)\n",
    "    except ValueError:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------------+----------+--------+--------+\n",
      "| Data Table |        Model        | Accuracy |  MAE   |  RMSE  |\n",
      "+------------+---------------------+----------+--------+--------+\n",
      "|    DF 1    |   Neural Network    |  0.8317  |        |        |\n",
      "|    DF 1    |         PCA         |  0.7822  |        |        |\n",
      "|    DF 1    |    Bootstrapping    |  0.7332  |        |        |\n",
      "|    DF 1    | K-nearest neighbors |  0.8713  |        |        |\n",
      "|    DF 2    |   Neural Network    |          | 0.3313 | 0.3564 |\n",
      "|    DF 2    |         PCA         |          | 0.4274 | 0.4774 |\n",
      "|    DF 2    |    Bootstrapping    |          | 0.3122 | 0.3408 |\n",
      "|    DF 2    | K-nearest neighbors |          | 0.1785 | 0.2515 |\n",
      "+------------+---------------------+----------+--------+--------+\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Set seeds round 1\n",
    "\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "seed_value = 23\n",
    "np.random.seed(seed_value) \n",
    "random.seed(seed_value) \n",
    "torch.manual_seed(seed_value) \n",
    "torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "\n",
    "\n",
    "# Neural Networks dataset 1\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = df1.drop(columns=['Depression'])\n",
    "y = df1['Depression'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "numerical_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.output = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x\n",
    "\n",
    "model = NeuralNet(input_size=X_train_tensor.shape[1])\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()  \n",
    "    predictions = model(X_test_tensor)\n",
    "    predicted_labels = (predictions >= 0.5).float()  \n",
    "\n",
    "    accuracy = accuracy_score(y_test_tensor.numpy(), predicted_labels.numpy())\n",
    "    df1_NN = accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Neural Networks dataset 2\n",
    "\n",
    "X = df2.drop(columns=['cgpa'])\n",
    "y = df2['cgpa']\n",
    "\n",
    "numerical_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.output = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x\n",
    "\n",
    "model = NeuralNet(input_size=X_train_tensor.shape[1])\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()  \n",
    "    predictions = model(X_test_tensor)\n",
    "    mae = torch.mean(torch.abs(predictions - y_test_tensor)).item()\n",
    "    df2_NN_MAE = mae\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    test_predictions = model(X_test_tensor)\n",
    "    mse = torch.mean((test_predictions - y_test_tensor) ** 2).item()\n",
    "    rmse = torch.sqrt(torch.tensor(mse)).item()\n",
    "    df2_NN_rmse = rmse\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# DF1 PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "X = df1.drop(columns=['Depression'])\n",
    "y = df1['Depression']\n",
    "\n",
    "y_encoded = y.map({'Yes': 1, 'No': 0}).values\n",
    "\n",
    "numerical_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "pca = PCA(n_components=2)  \n",
    "X_pca = pca.fit_transform(X_preprocessed)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.output = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x\n",
    "\n",
    "model = NeuralNet(input_size=X_train_tensor.shape[1])\n",
    "criterion = nn.BCELoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(X_train_tensor)\n",
    "    loss = criterion(predictions, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    test_predictions = model(X_test_tensor)\n",
    "    test_predictions_class = (test_predictions > 0.5).float()  \n",
    "\n",
    "    accuracy = accuracy_score(y_test, test_predictions_class.numpy())\n",
    "    df1_PCA = accuracy\n",
    "\n",
    "\n",
    "\n",
    "# DF2 PCA\n",
    "\n",
    "\n",
    "X = df2.drop(columns=['cgpa'])  \n",
    "y = df2['cgpa']  \n",
    "\n",
    "numerical_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "pca = PCA(n_components=2)  \n",
    "X_pca = pca.fit_transform(X_preprocessed)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.output = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.output(x)\n",
    "\n",
    "model = NeuralNet(input_size=X_train_tensor.shape[1])\n",
    "criterion = nn.MSELoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(X_train_tensor)\n",
    "    loss = criterion(predictions, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    test_predictions = model(X_test_tensor)\n",
    "\n",
    "    mse = torch.mean((test_predictions - y_test_tensor) ** 2).item()\n",
    "    rmse = torch.sqrt(torch.tensor(mse)).item()\n",
    "    df2_PCA_RMSE = rmse\n",
    "\n",
    "    mae = torch.mean(torch.abs(test_predictions - y_test_tensor)).item()\n",
    "    df2_PCA_MAE = mae\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# DF1 Bootstrapping\n",
    "\n",
    "\n",
    "X = df1.drop(columns=['Depression']) \n",
    "y = df1['Depression']\n",
    "\n",
    "y_encoded = y.map({'Yes': 1, 'No': 0}).values\n",
    "\n",
    "numerical_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "pca = PCA(n_components=2) \n",
    "X_pca = pca.fit_transform(X_preprocessed)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "\n",
    "n_bootstrap = 100\n",
    "accuracy_list = []\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.output = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x\n",
    "\n",
    "for i in range(n_bootstrap):\n",
    "    bootstrap_indices = np.random.choice(range(len(X_train_tensor)), size=len(X_train_tensor), replace=True)\n",
    "    X_train_bootstrap = X_train_tensor[bootstrap_indices]\n",
    "    y_train_bootstrap = y_train_tensor[bootstrap_indices]\n",
    "    \n",
    "    model = NeuralNet(input_size=X_train_tensor.shape[1])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.BCELoss()  \n",
    "\n",
    "    for epoch in range(10):  \n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(X_train_bootstrap)\n",
    "        loss = criterion(predictions, y_train_bootstrap)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_predictions = model(X_test_tensor)\n",
    "        test_predictions_class = (test_predictions > 0.5).float()  \n",
    "        acc = accuracy_score(y_test_tensor.cpu().numpy(), test_predictions_class.cpu().numpy())\n",
    "        accuracy_list.append(acc)\n",
    "\n",
    "mean_accuracy = np.mean(accuracy_list)\n",
    "std_accuracy = np.std(accuracy_list)\n",
    "df1_boot_acc = mean_accuracy\n",
    "df1_boot_stdev = std_accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# DF2 Bootstrapping\n",
    "\n",
    "X = df2.drop(columns=['cgpa'])\n",
    "y = df2['cgpa']\n",
    "\n",
    "numerical_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "n_bootstrap = 100\n",
    "rmse_list = []\n",
    "mae_list = []\n",
    "\n",
    "for i in range(n_bootstrap):\n",
    "    bootstrap_indices = np.random.choice(range(len(X_train)), size=len(X_train), replace=True)\n",
    "    X_train_bootstrap = X_train_tensor[bootstrap_indices]\n",
    "    y_train_bootstrap = y_train_tensor[bootstrap_indices]\n",
    "    \n",
    "    model = NeuralNet(input_size=X_train_tensor.shape[1])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    for epoch in range(10):  \n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(X_train_bootstrap)\n",
    "        loss = criterion(predictions, y_train_bootstrap)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_predictions = model(X_test_tensor)\n",
    "        mse = torch.mean((test_predictions - y_test_tensor) ** 2).item()\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = torch.mean(torch.abs(test_predictions - y_test_tensor)).item()\n",
    "        rmse_list.append(rmse)\n",
    "        mae_list.append(mae)\n",
    "\n",
    "df2_boot_rmse = np.mean(rmse_list)\n",
    "df2_boot_mae = np.mean(mae_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# DF1 KNN\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X = df1.drop(columns=['Depression'])\n",
    "y = df1['Depression']\n",
    "\n",
    "y_encoded = y.map({'Yes': 1, 'No': 0}).values\n",
    "\n",
    "numerical_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)  \n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "df1_KNN = accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# DF2 KNN\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "X = df2.drop(columns=['cgpa'])  \n",
    "y = df2['cgpa']  \n",
    "\n",
    "numerical_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),  \n",
    "        ('cat', OneHotEncoder(), categorical_cols)   \n",
    "    ]\n",
    ")\n",
    "\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=5)  \n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "df2_KNN_rmse = rmse\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "df2_KNN_mae = mae\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "new_table = {\n",
    "    'Data Table': ['DF 1', 'DF 1', 'DF 1', 'DF 1', 'DF 2', 'DF 2', 'DF 2', 'DF 2'],\n",
    "    'Model': ['Neural Network', 'PCA', 'Bootstrapping', 'K-nearest neighbors', 'Neural Network', 'PCA', 'Bootstrapping', 'K-nearest neighbors'],\n",
    "    'Accuracy': [df1_NN, df1_PCA, df1_boot_acc, df1_KNN, None, None, None, None],\n",
    "    'MAE': [None, None, None, None, df2_NN_MAE, df2_PCA_MAE, df2_boot_mae, df2_KNN_mae],\n",
    "    'RMSE': [None, None, None, None, df2_NN_rmse, df2_PCA_RMSE, df2_boot_rmse, df2_KNN_rmse]\n",
    "}\n",
    "\n",
    "df3 = pd.DataFrame(new_table)\n",
    "df3[['Accuracy', 'MAE', 'RMSE']] = df3[['Accuracy', 'MAE', 'RMSE']].round(4)\n",
    "df3 = df3.fillna(\"\")\n",
    "\n",
    "\n",
    "print(tabulate(df3, headers='keys', tablefmt='pretty', showindex=False))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------------+----------+--------+--------+\n",
      "| Data Table |        Model        | Accuracy |  MAE   |  RMSE  |\n",
      "+------------+---------------------+----------+--------+--------+\n",
      "|    DF 1    |   Neural Network    |  0.703   |        |        |\n",
      "|    DF 1    |         PCA         |  0.7624  |        |        |\n",
      "|    DF 1    |    Bootstrapping    |  0.753   |        |        |\n",
      "|    DF 1    | K-nearest neighbors |  0.8713  |        |        |\n",
      "|    DF 2    |   Neural Network    |          | 0.3283 | 0.3549 |\n",
      "|    DF 2    |         PCA         |          | 0.4484 | 0.4966 |\n",
      "|    DF 2    |    Bootstrapping    |          | 0.3186 | 0.3467 |\n",
      "|    DF 2    | K-nearest neighbors |          | 0.1785 | 0.2515 |\n",
      "+------------+---------------------+----------+--------+--------+\n"
     ]
    }
   ],
   "source": [
    "## Set seeds round 2\n",
    "\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "seed_value = 97\n",
    "np.random.seed(seed_value) \n",
    "random.seed(seed_value) \n",
    "torch.manual_seed(seed_value) \n",
    "torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "\n",
    "\n",
    "# Neural Networks dataset 1\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = df1.drop(columns=['Depression'])\n",
    "y = df1['Depression'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "numerical_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.output = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x\n",
    "\n",
    "model = NeuralNet(input_size=X_train_tensor.shape[1])\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()  \n",
    "    predictions = model(X_test_tensor)\n",
    "    predicted_labels = (predictions >= 0.5).float()  \n",
    "\n",
    "    accuracy = accuracy_score(y_test_tensor.numpy(), predicted_labels.numpy())\n",
    "    df1_NN = accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Neural Networks dataset 2\n",
    "\n",
    "X = df2.drop(columns=['cgpa'])\n",
    "y = df2['cgpa']\n",
    "\n",
    "numerical_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.output = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x\n",
    "\n",
    "model = NeuralNet(input_size=X_train_tensor.shape[1])\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()  \n",
    "    predictions = model(X_test_tensor)\n",
    "    mae = torch.mean(torch.abs(predictions - y_test_tensor)).item()\n",
    "    df2_NN_MAE = mae\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    test_predictions = model(X_test_tensor)\n",
    "    mse = torch.mean((test_predictions - y_test_tensor) ** 2).item()\n",
    "    rmse = torch.sqrt(torch.tensor(mse)).item()\n",
    "    df2_NN_rmse = rmse\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# DF1 PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "X = df1.drop(columns=['Depression'])\n",
    "y = df1['Depression']\n",
    "\n",
    "y_encoded = y.map({'Yes': 1, 'No': 0}).values\n",
    "\n",
    "numerical_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "pca = PCA(n_components=2)  \n",
    "X_pca = pca.fit_transform(X_preprocessed)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.output = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x\n",
    "\n",
    "model = NeuralNet(input_size=X_train_tensor.shape[1])\n",
    "criterion = nn.BCELoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(X_train_tensor)\n",
    "    loss = criterion(predictions, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    test_predictions = model(X_test_tensor)\n",
    "    test_predictions_class = (test_predictions > 0.5).float()  \n",
    "\n",
    "    accuracy = accuracy_score(y_test, test_predictions_class.numpy())\n",
    "    df1_PCA = accuracy\n",
    "\n",
    "\n",
    "\n",
    "# DF2 PCA\n",
    "\n",
    "\n",
    "X = df2.drop(columns=['cgpa'])  \n",
    "y = df2['cgpa']  \n",
    "\n",
    "numerical_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "pca = PCA(n_components=2)  \n",
    "X_pca = pca.fit_transform(X_preprocessed)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.output = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.output(x)\n",
    "\n",
    "model = NeuralNet(input_size=X_train_tensor.shape[1])\n",
    "criterion = nn.MSELoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(X_train_tensor)\n",
    "    loss = criterion(predictions, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    test_predictions = model(X_test_tensor)\n",
    "\n",
    "    mse = torch.mean((test_predictions - y_test_tensor) ** 2).item()\n",
    "    rmse = torch.sqrt(torch.tensor(mse)).item()\n",
    "    df2_PCA_RMSE = rmse\n",
    "\n",
    "    mae = torch.mean(torch.abs(test_predictions - y_test_tensor)).item()\n",
    "    df2_PCA_MAE = mae\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# DF1 Bootstrapping\n",
    "\n",
    "\n",
    "X = df1.drop(columns=['Depression']) \n",
    "y = df1['Depression']\n",
    "\n",
    "y_encoded = y.map({'Yes': 1, 'No': 0}).values\n",
    "\n",
    "numerical_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "pca = PCA(n_components=2) \n",
    "X_pca = pca.fit_transform(X_preprocessed)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "\n",
    "n_bootstrap = 100\n",
    "accuracy_list = []\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.output = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x\n",
    "\n",
    "for i in range(n_bootstrap):\n",
    "    bootstrap_indices = np.random.choice(range(len(X_train_tensor)), size=len(X_train_tensor), replace=True)\n",
    "    X_train_bootstrap = X_train_tensor[bootstrap_indices]\n",
    "    y_train_bootstrap = y_train_tensor[bootstrap_indices]\n",
    "    \n",
    "    model = NeuralNet(input_size=X_train_tensor.shape[1])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.BCELoss()  \n",
    "\n",
    "    for epoch in range(10):  \n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(X_train_bootstrap)\n",
    "        loss = criterion(predictions, y_train_bootstrap)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_predictions = model(X_test_tensor)\n",
    "        test_predictions_class = (test_predictions > 0.5).float()  \n",
    "        acc = accuracy_score(y_test_tensor.cpu().numpy(), test_predictions_class.cpu().numpy())\n",
    "        accuracy_list.append(acc)\n",
    "\n",
    "mean_accuracy = np.mean(accuracy_list)\n",
    "std_accuracy = np.std(accuracy_list)\n",
    "df1_boot_acc = mean_accuracy\n",
    "df1_boot_stdev = std_accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# DF2 Bootstrapping\n",
    "\n",
    "X = df2.drop(columns=['cgpa'])\n",
    "y = df2['cgpa']\n",
    "\n",
    "numerical_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "n_bootstrap = 100\n",
    "rmse_list = []\n",
    "mae_list = []\n",
    "\n",
    "for i in range(n_bootstrap):\n",
    "    bootstrap_indices = np.random.choice(range(len(X_train)), size=len(X_train), replace=True)\n",
    "    X_train_bootstrap = X_train_tensor[bootstrap_indices]\n",
    "    y_train_bootstrap = y_train_tensor[bootstrap_indices]\n",
    "    \n",
    "    model = NeuralNet(input_size=X_train_tensor.shape[1])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    for epoch in range(10):  \n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(X_train_bootstrap)\n",
    "        loss = criterion(predictions, y_train_bootstrap)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_predictions = model(X_test_tensor)\n",
    "        mse = torch.mean((test_predictions - y_test_tensor) ** 2).item()\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = torch.mean(torch.abs(test_predictions - y_test_tensor)).item()\n",
    "        rmse_list.append(rmse)\n",
    "        mae_list.append(mae)\n",
    "\n",
    "df2_boot_rmse = np.mean(rmse_list)\n",
    "df2_boot_mae = np.mean(mae_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# DF1 KNN\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X = df1.drop(columns=['Depression'])\n",
    "y = df1['Depression']\n",
    "\n",
    "y_encoded = y.map({'Yes': 1, 'No': 0}).values\n",
    "\n",
    "numerical_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)  \n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "df1_KNN = accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# DF2 KNN\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "X = df2.drop(columns=['cgpa'])  \n",
    "y = df2['cgpa']  \n",
    "\n",
    "numerical_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),  \n",
    "        ('cat', OneHotEncoder(), categorical_cols)   \n",
    "    ]\n",
    ")\n",
    "\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=5)  \n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "df2_KNN_rmse = rmse\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "df2_KNN_mae = mae\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "new_table2 = {\n",
    "    'Data Table': ['DF 1', 'DF 1', 'DF 1', 'DF 1', 'DF 2', 'DF 2', 'DF 2', 'DF 2'],\n",
    "    'Model': ['Neural Network', 'PCA', 'Bootstrapping', 'K-nearest neighbors', 'Neural Network', 'PCA', 'Bootstrapping', 'K-nearest neighbors'],\n",
    "    'Accuracy': [df1_NN, df1_PCA, df1_boot_acc, df1_KNN, None, None, None, None],\n",
    "    'MAE': [None, None, None, None, df2_NN_MAE, df2_PCA_MAE, df2_boot_mae, df2_KNN_mae],\n",
    "    'RMSE': [None, None, None, None, df2_NN_rmse, df2_PCA_RMSE, df2_boot_rmse, df2_KNN_rmse]\n",
    "}\n",
    "\n",
    "df4 = pd.DataFrame(new_table2)\n",
    "df4[['Accuracy', 'MAE', 'RMSE']] = df4[['Accuracy', 'MAE', 'RMSE']].round(4)\n",
    "df4 = df4.fillna(\"\")\n",
    "\n",
    "print(tabulate(df4, headers='keys', tablefmt='pretty', showindex=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
